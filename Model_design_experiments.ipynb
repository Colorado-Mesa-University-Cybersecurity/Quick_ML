{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import fastai\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler\n",
    ")\n",
    "\n",
    "from typing import (\n",
    "    Callable,\n",
    "    Dict,\n",
    "    List,\n",
    "    Tuple\n",
    ")\n",
    "\n",
    "from Quick.cleaning.loading import (\n",
    "    examine_dataset,\n",
    "    remove_infs_and_nans\n",
    ")\n",
    "\n",
    "from Quick.cleaning.utils import (\n",
    "    get_file_path\n",
    ")\n",
    "\n",
    "from Quick.runners.deep import (\n",
    "    run_deep_nn_experiment\n",
    ")\n",
    "\n",
    "from Quick.runners.residual import (\n",
    "    run_residual_deep_nn_experiment\n",
    ")\n",
    "\n",
    "from Quick.runners.sk import (\n",
    "    run_sk_experiment\n",
    ")\n",
    "\n",
    "from Quick.runners.torch import (\n",
    "    run_torch_nn_experiment\n",
    ")\n",
    "\n",
    "from rff.layers import (\n",
    "    GaussianEncoding,\n",
    ")\n",
    "\n",
    "\n",
    "from Quick.constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "print(torch.backends.mps.is_available())\n",
    "print(torch.backends.mps.is_built())\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 0/1: We now look at ./data/03-11/Syn.csv\n",
      "\n",
      "\n",
      "Loading Dataset: ./data/03-11/Syn.csv\n",
      "\tTo Dataset Cache: ./cache/Syn.csv.pickle\n",
      "\n",
      "\n",
      "        File:\t\t\t\t./data/03-11/Syn.csv  \n",
      "        Job Number:\t\t\t0\n",
      "        Shape:\t\t\t\t(4320541, 88)\n",
      "        Samples:\t\t\t4320541 \n",
      "        Features:\t\t\t88\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "data_path_1: str = './data/'\n",
    "data_path_2: str = './data/03-11/'\n",
    "data_sets_1: list = [\n",
    "    'Darknet_experiments_base.csv',\n",
    "    'airline-passengers.csv',\n",
    "]\n",
    "data_sets_2: list = [\n",
    "    'Syn.csv',\n",
    "]\n",
    "\n",
    "file_path_1: callable = get_file_path(data_path_1)\n",
    "file_path_2: callable = get_file_path(data_path_2)\n",
    "file_set_1: list = list(map(file_path_1, data_sets_1))\n",
    "file_set_2: list = list(map(file_path_2, data_sets_2))\n",
    "current_job: int = 0\n",
    "\n",
    "# dataset_1 = examine_dataset(0, file_set_1, data_sets_1)\n",
    "# dataset_2 = examine_dataset(1, file_set_1, data_sets_1)\n",
    "dataset_3 = examine_dataset(0, file_set_2, data_sets_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we try to use the darknet dataset to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darknet = dataset_2['Dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darknet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darknet_no_label = darknet.drop(columns=['Traffic Type', 'Application Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darknet_no_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split for time series\n",
    "train_size = int(len(darknet_no_label) * 0.67)\n",
    "test_size = len(darknet_no_label) - train_size\n",
    "train, test = darknet_no_label[:train_size], darknet_no_label[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we standardize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# train-test split for time series\n",
    "# df_downsampled = darknet_no_label.sample(frac=0.1, random_state=42)\n",
    "df_downsampled = darknet_no_label.copy()\n",
    "\n",
    "scaler.fit(df_downsampled)\n",
    "df_downsampled = scaler.transform(df_downsampled)\n",
    "\n",
    "train_size = int(len(df_downsampled) * 0.67)\n",
    "test_size = len(df_downsampled) - train_size\n",
    "train, test = df_downsampled[:train_size], df_downsampled[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, lookback, device):\n",
    "    \"\"\"Transform a time series into a prediction dataset\n",
    "    \n",
    "    Args:\n",
    "        dataset: A numpy array of time series, first dimension is the time steps\n",
    "        lookback: Size of window for prediction\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(dataset)-lookback):\n",
    "        feature = dataset[i:i+lookback]\n",
    "        target = dataset[i+lookback:i+lookback+1]\n",
    "        X.append(feature)\n",
    "        y.append(target)\n",
    "\n",
    "\n",
    "\n",
    "    # print(len(X), len(y))\n",
    "    print((X:=np.array(X)).shape, (y := np.array(y)).shape)\n",
    "    return torch.tensor(X.astype('float32'), device=device), torch.tensor(y.astype('float32'), device=device)\n",
    "\n",
    "\n",
    "lookback = 10\n",
    "X_train, y_train = create_dataset(train, lookback=lookback, device = device)\n",
    "X_test, y_test = create_dataset(test, lookback=lookback, device = device)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "# for i in range(1, 10):\n",
    "#     print(X_train.shape)\n",
    "#     # print(X_train[i])\n",
    "#     # ts, vs = X_train[i].shape\n",
    "#     print(X_train[i])\n",
    "#     print(X_train[i].permute(1, 0))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# nn.MultiheadAttention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class AirModel(nn.Module):\n",
    "    def __init__(self, input_size, lookback_size, embedding_size=200):\n",
    "        super().__init__()\n",
    "        # self.lstm = nn.LSTM(input_size=input_size, hidden_size=embedding_size, num_layers=1, batch_first=True)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.unflat = nn.Unflatten(0, (-1, 1))\n",
    "        self.cont_embed = nn.Sequential(\n",
    "            nn.Flatten(0, 1),\n",
    "            nn.Linear(input_size, embedding_size),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(embedding_size, embedding_size),\n",
    "            nn.Unflatten(0, (-1, lookback_size))\n",
    "        )\n",
    "\n",
    "        # we need a regression head to predict the next item in the sequence of shape \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(lookback*embedding_size, lookback*embedding_size),\n",
    "            # nn.BatchNorm1d(lookback_size*embedding_size),\n",
    "            # nn.LayerNorm(lookback*embedding_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(lookback*embedding_size, lookback*embedding_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(lookback*embedding_size, input_size),\n",
    "            # nn.ReLU(),\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm((lookback_size, embedding_size))\n",
    "\n",
    "        self.query = nn.Linear(embedding_size, embedding_size)\n",
    "        self.key = nn.Linear(embedding_size, embedding_size)\n",
    "        self.value = nn.Linear(embedding_size, embedding_size)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.norm2 = nn.LayerNorm(embedding_size)\n",
    "        self.norm3 = nn.LayerNorm(embedding_size)\n",
    "\n",
    "        \n",
    "\n",
    "        self.pos_embed = nn.Embedding(lookback_size, embedding_size)\n",
    "        # self.linear = nn.Linear(lookback*embedding_size, input_size)\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        # x = self.cont_embed(x)\n",
    "        x = self.cont_embed(x) + self.pos_embed(torch.arange(x.shape[1]))\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        query = self.query(x)\n",
    "        key = self.key(x)\n",
    "        value = self.value(x)\n",
    "\n",
    "        # print(query.shape, key.shape, value.shape)\n",
    "\n",
    "        pre_attention = self.softmax(torch.matmul(query, key.transpose(-2, -1)))\n",
    "        # print(pre_attention.shape)\n",
    "\n",
    "        attention = torch.matmul(pre_attention, value)\n",
    "        # print(attention.shape)\n",
    "\n",
    "        x = self.norm2(x + attention)\n",
    "\n",
    "        # print(x.shape)\n",
    "\n",
    "        # we mix the signals together\n",
    "        x = self.flat(x)\n",
    "        x = self.head(x)\n",
    "        x = self.unflat(x)\n",
    "\n",
    "        # print(x.shape)\n",
    "\n",
    "        \n",
    "        # x = self.flat(x)\n",
    "        # x, _ = self.lstm(x)\n",
    "        # # print(x.shape)\n",
    "        # x = self.flat(x)\n",
    "        # # print(x.shape)\n",
    "        # x = self.linear(x)\n",
    "        # x = self.unflat(x)\n",
    "        # # print(x.shape)\n",
    "\n",
    "        # we stop for debugging\n",
    "        # print('stopping')\n",
    "        # raise Exception('stop')\n",
    "        return x\n",
    "\n",
    "\n",
    "# model = AirModel(input_size=62, lookback_size=lookback)\n",
    "# y_pred = model(X_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class AirModel(nn.Module):\n",
    "    def __init__(self, input_size, lookback_size, device, embedding_size=200):\n",
    "        super().__init__()\n",
    "        # self.lstm = nn.LSTM(input_size=input_size, hidden_size=embedding_size, num_layers=1, batch_first=True)\n",
    "        self.embedding_size = embedding_size\n",
    "        self.flat = nn.Flatten()\n",
    "        self.unflat = nn.Unflatten(0, (-1, 1))\n",
    "        self.cont_embed = nn.Sequential(\n",
    "            nn.Flatten(0, 1),\n",
    "            nn.Linear(input_size, embedding_size, device = device),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(embedding_size, embedding_size),\n",
    "            nn.Unflatten(0, (-1, lookback_size))\n",
    "        )\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        # we need a regression head to predict the next item in the sequence of shape \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(lookback*embedding_size, lookback*embedding_size, device = device),\n",
    "            # nn.BatchNorm1d(lookback_size*embedding_size),\n",
    "            # nn.LayerNorm(lookback*embedding_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(lookback*embedding_size, lookback*embedding_size, device = device),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(lookback*embedding_size, input_size, device = device),\n",
    "            # nn.ReLU(),\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm((lookback_size, embedding_size), device = device)\n",
    "\n",
    "        self.query = nn.Linear(embedding_size, embedding_size, device = device)\n",
    "        self.key = nn.Linear(embedding_size, embedding_size, device = device)\n",
    "        self.value = nn.Linear(embedding_size, embedding_size, device = device)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.norm2 = nn.LayerNorm(embedding_size, device = device)\n",
    "        self.norm3 = nn.LayerNorm(embedding_size, device = device)\n",
    "\n",
    "        \n",
    "\n",
    "        self.pos_embed = nn.Embedding(lookback_size, embedding_size, device = device)\n",
    "        # self.linear = nn.Linear(lookback*embedding_size, input_size)\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        # x = self.cont_embed(x)\n",
    "        x = self.cont_embed(x) + self.pos_embed(torch.arange(x.shape[1], device = self.device))\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        query = self.query(x)\n",
    "        key = self.key(x)\n",
    "        value = self.value(x)\n",
    "\n",
    "        # print(query.shape, key.shape, value.shape)\n",
    "\n",
    "        pre_attention = self.softmax(torch.matmul(query, key.transpose(-2, -1))/torch.sqrt(torch.tensor(self.embedding_size, dtype=torch.float32)))\n",
    "        \n",
    "        # print(pre_attention.shape)\n",
    "\n",
    "        attention = torch.matmul(pre_attention, value)\n",
    "        # print(attention.shape)\n",
    "\n",
    "        x = self.norm2(x + attention)\n",
    "\n",
    "        # print(x.shape)\n",
    "\n",
    "        # we mix the signals together\n",
    "        x = self.flat(x)\n",
    "        x = self.head(x)\n",
    "        x = self.unflat(x)\n",
    "\n",
    "        # print(x.shape)\n",
    "\n",
    "        \n",
    "        # x = self.flat(x)\n",
    "        # x, _ = self.lstm(x)\n",
    "        # # print(x.shape)\n",
    "        # x = self.flat(x)\n",
    "        # # print(x.shape)\n",
    "        # x = self.linear(x)\n",
    "        # x = self.unflat(x)\n",
    "        # # print(x.shape)\n",
    "\n",
    "        # we stop for debugging\n",
    "        # print('stopping')\n",
    "        # raise Exception('stop')\n",
    "        return x\n",
    "\n",
    "\n",
    "# model = AirModel(input_size=62, lookback_size=lookback, device = device)\n",
    "# y_pred = model(X_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# failed model\n",
    "class AirModel(nn.Module):\n",
    "    def __init__(self, input_size, lookback_size, device, embedding_size=80, heads = 2):\n",
    "        super().__init__()\n",
    "        # self.lstm = nn.LSTM(input_size=input_size, hidden_size=embedding_size, num_layers=1, batch_first=True)\n",
    "        self.embedding_size = embedding_size\n",
    "        self.device = device\n",
    "        self.flat1 = nn.Flatten(0, 1)\n",
    "        self.flat2 = nn.Flatten()\n",
    "        self.unflat1 = nn.Unflatten(0, (-1, lookback_size, embedding_size))\n",
    "        self.unflat2 = nn.Unflatten(0, (-1, 1))\n",
    "        self.cont_embed = nn.Sequential(\n",
    "            nn.Flatten(0, 1),\n",
    "            nn.Linear(input_size, embedding_size, device = device),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(embedding_size, embedding_size),\n",
    "            nn.Unflatten(0, (-1, lookback_size))\n",
    "        )\n",
    "\n",
    "        # we need a regression head to predict the next item in the sequence of shape \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(lookback*embedding_size, lookback*embedding_size, device = device),\n",
    "            # nn.BatchNorm1d(lookback_size*embedding_size),\n",
    "            # nn.LayerNorm(lookback*embedding_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_size, embedding_size, device = device),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_size, input_size, device = device),\n",
    "            # nn.ReLU(),\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm((lookback_size, embedding_size), device = device)\n",
    "        self.norm2 = nn.LayerNorm(embedding_size, device = device)\n",
    "\n",
    "\n",
    "        self.mh_attention = nn.MultiheadAttention(embed_dim=embedding_size, num_heads=heads, dropout=0.1, device = device)\n",
    "        \n",
    "\n",
    "        self.pos_embed = nn.Embedding(lookback_size, embedding_size, device = device)\n",
    "        # self.linear = nn.Linear(lookback*embedding_size, input_size)\n",
    "    def forward(self, x):\n",
    "        batch_size, lookback_size, input_size = x.shape\n",
    "\n",
    "        x = self.cont_embed(x) + self.pos_embed(torch.arange(x.shape[1], device = self.device))\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        attention, _ = self.mh_attention(x, x, x)\n",
    "\n",
    "        x = self.norm1(x + attention)\n",
    "\n",
    "        # print(x.shape)\n",
    "\n",
    "\n",
    "        print(x.shape)\n",
    "\n",
    "        # x = x.reshape(batch_size, lookback_size, self.embedding_size)\n",
    "        # print(x.shape)\n",
    "\n",
    "\n",
    "        # we mix the signals together\n",
    "        x = self.flat2(x)\n",
    "        x = self.head(x)\n",
    "        x = self.unflat2(x)\n",
    "\n",
    "        # print(x.shape)\n",
    "\n",
    "        \n",
    "        # x = self.flat(x)\n",
    "        # x, _ = self.lstm(x)\n",
    "        # # print(x.shape)\n",
    "        # x = self.flat(x)\n",
    "        # # print(x.shape)\n",
    "        # x = self.linear(x)\n",
    "        # x = self.unflat(x)\n",
    "        # # print(x.shape)\n",
    "\n",
    "        # we stop for debugging\n",
    "        # print('stopping')\n",
    "        # raise Exception('stop')\n",
    "        return x\n",
    "\n",
    "\n",
    "model = AirModel(input_size=62, lookback_size=lookback)\n",
    "y_pred = model(X_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# failed model\n",
    "class AirModel(nn.Module):\n",
    "    def __init__(self, input_size, lookback_size, device, embedding_size=100, heads = 2):\n",
    "        super().__init__()\n",
    "        # self.lstm = nn.LSTM(input_size=input_size, hidden_size=embedding_size, num_layers=1, batch_first=True)\n",
    "        self.embedding_size = embedding_size\n",
    "        self.device = device\n",
    "        self.flat1 = nn.Flatten(0, 1)\n",
    "        self.flat2 = nn.Flatten()\n",
    "        self.unflat1 = nn.Unflatten(0, (-1, lookback_size, embedding_size))\n",
    "        self.unflat2 = nn.Unflatten(0, (-1, 1))\n",
    "        self.cont_embed = nn.Sequential(\n",
    "            nn.Flatten(0, 1),\n",
    "            nn.Linear(input_size, embedding_size, device = device),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_size, embedding_size),\n",
    "            nn.Unflatten(0, (-1, lookback_size))\n",
    "        )\n",
    "\n",
    "        # we need a regression head to predict the next item in the sequence of shape \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(lookback*embedding_size, lookback*embedding_size, device = device),\n",
    "            # nn.BatchNorm1d(lookback_size*embedding_size),\n",
    "            # nn.LayerNorm(lookback*embedding_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_size, embedding_size, device = device),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_size, input_size, device = device),\n",
    "            # nn.ReLU(),\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm((lookback_size, embedding_size), device = device)\n",
    "        self.norm2 = nn.LayerNorm(embedding_size, device = device)\n",
    "\n",
    "\n",
    "        self.mh_attention = nn.MultiheadAttention(embed_dim=embedding_size, num_heads=heads, dropout=0.1, device = device)\n",
    "        \n",
    "\n",
    "        self.pos_embed = nn.Embedding(lookback_size, embedding_size, device = device)\n",
    "        # self.linear = nn.Linear(lookback*embedding_size, input_size)\n",
    "    def forward(self, x):\n",
    "        batch_size, lookback_size, input_size = x.shape\n",
    "\n",
    "        x = self.cont_embed(x) + self.pos_embed(torch.arange(x.shape[1], device = self.device))\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        attention, _ = self.mh_attention(x, x, x)\n",
    "\n",
    "        x = self.norm1(x + attention)\n",
    "\n",
    "        # print(x.shape)\n",
    "\n",
    "\n",
    "        print(x.shape)\n",
    "\n",
    "        # x = x.reshape(batch_size, lookback_size, self.embedding_size)\n",
    "        # print(x.shape)\n",
    "\n",
    "\n",
    "        # we mix the signals together\n",
    "        x = self.flat2(x)\n",
    "        x = self.head(x)\n",
    "        x = self.unflat2(x)\n",
    "\n",
    "        # print(x.shape)\n",
    "\n",
    "        \n",
    "        # x = self.flat(x)\n",
    "        # x, _ = self.lstm(x)\n",
    "        # # print(x.shape)\n",
    "        # x = self.flat(x)\n",
    "        # # print(x.shape)\n",
    "        # x = self.linear(x)\n",
    "        # x = self.unflat(x)\n",
    "        # # print(x.shape)\n",
    "\n",
    "        # we stop for debugging\n",
    "        # print('stopping')\n",
    "        # raise Exception('stop')\n",
    "        return x\n",
    "\n",
    "\n",
    "model = AirModel(input_size=62, lookback_size=lookback)\n",
    "y_pred = model(X_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "batch_size = 16\n",
    "model = AirModel(input_size=62, lookback_size=lookback, device = device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=.01)\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "# we want to use the ranger optimizer\n",
    "# optimizer = optim.RAdam(model.parameters())\n",
    "loss_fn = nn.MSELoss()\n",
    "# loss_fn = nn.L1Loss()\n",
    "# log likelihood loss\n",
    "# loss_fn = nn.GaussianNLLLoss()\n",
    "# we need to gradient clip because the LSTM is very sensitive to exploding gradients\n",
    "# https://stackoverflow.com/questions/54716377/pytorch-why-do-we-need-to-set-the-gradients-manually-to-zero-in-pytorch\n",
    "# https://stackoverflow.com/questions/55735643/how-to-use-clip-grad-norm-in-pytorch\n",
    "loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=batch_size)\n",
    "\n",
    "avg_train_loss = []\n",
    "avg_test_loss = []\n",
    "\n",
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in loader:\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # Validation\n",
    "    # if epoch % 100 != 0:\n",
    "    #     continue\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_train_pred = model(X_train).cpu()\n",
    "        train_rmse = np.sqrt(loss_fn(y_train_pred, y_train.cpu()))\n",
    "        y_test_pred = model(X_test).cpu()\n",
    "        test_rmse = np.sqrt(loss_fn(y_test_pred, y_test.cpu()))\n",
    "    avg_train_loss.append(train_rmse)\n",
    "    avg_test_loss.append(test_rmse)\n",
    "    difference_train = avg_train_loss[-1] - avg_train_loss[-2] if len(avg_train_loss) > 1 else 0\n",
    "    difference_test = avg_test_loss[-1] - avg_test_loss[-2] if len(avg_test_loss) > 1 else 0\n",
    "    print(\"Epoch %d: train RMSE %.4f, test RMSE %.4f, diff train %.4f, diff test %.4f\" % (epoch, train_rmse, test_rmse, difference_train, difference_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 64\n",
    "# loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=batch_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=.1)\n",
    "n_epochs = 50\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in loader:\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # Validation\n",
    "    # if epoch % 100 != 0:\n",
    "    #     continue\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_train_pred = model(X_train).cpu()\n",
    "        train_rmse = np.sqrt(loss_fn(y_train_pred, y_train.cpu()))\n",
    "        y_test_pred = model(X_test).cpu()\n",
    "        test_rmse = np.sqrt(loss_fn(y_test_pred, y_test.cpu()))\n",
    "    avg_train_loss.append(train_rmse)\n",
    "    avg_test_loss.append(test_rmse)\n",
    "    difference_train = avg_train_loss[-1] - avg_train_loss[-2] if len(avg_train_loss) > 1 else 0\n",
    "    difference_test = avg_test_loss[-1] - avg_test_loss[-2] if len(avg_test_loss) > 1 else 0\n",
    "    print(\"Epoch %d: train RMSE %.4f, test RMSE %.4f, diff train %.4f, diff test %.4f\" % (epoch, train_rmse, test_rmse, difference_train, difference_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "batch_size = 32\n",
    "model = AirModel(input_size=62, lookback_size=lookback)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "# we want to use the ranger optimizer\n",
    "# optimizer = optim.RAdam(model.parameters())\n",
    "loss_fn = nn.MSELoss()\n",
    "# we need to gradient clip because the LSTM is very sensitive to exploding gradients\n",
    "# https://stackoverflow.com/questions/54716377/pytorch-why-do-we-need-to-set-the-gradients-manually-to-zero-in-pytorch\n",
    "# https://stackoverflow.com/questions/55735643/how-to-use-clip-grad-norm-in-pytorch\n",
    "loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=batch_size)\n",
    "\n",
    "avg_train_loss = []\n",
    "avg_test_loss = []\n",
    "\n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in loader:\n",
    "        y_pred = model(X_batch)\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimizer.zero_grad()\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "    # Validation\n",
    "    # if epoch % 100 != 0:\n",
    "    #     continue\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_train)\n",
    "        train_rmse = np.sqrt(loss_fn(y_pred, y_train))\n",
    "        y_pred = model(X_test)\n",
    "        test_rmse = np.sqrt(loss_fn(y_pred, y_test))\n",
    "    avg_train_loss.append(train_rmse)\n",
    "    avg_test_loss.append(test_rmse)\n",
    "    difference_train = avg_train_loss[-1] - avg_train_loss[-2] if len(avg_train_loss) > 1 else 0\n",
    "    difference_test = avg_test_loss[-1] - avg_test_loss[-2] if len(avg_test_loss) > 1 else 0\n",
    "    print(\"Epoch %d: train RMSE %.4f, test RMSE %.4f, diff train %.4f, diff test %.4f\" % (epoch, train_rmse, test_rmse, difference_train, difference_test))\n",
    "    #  train avg %.1f, test avg %.1f\" % (epoch, train_rmse, test_rmse, np.mean(avg_train_loss), np.mean(avg_test_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "model = AirModel(input_size=62, lookback_size=lookback)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "# we want to use the ranger optimizer\n",
    "# optimizer = optim.RAdam(model.parameters())\n",
    "loss_fn = nn.MSELoss()\n",
    "# we need to gradient clip because the LSTM is very sensitive to exploding gradients\n",
    "# https://stackoverflow.com/questions/54716377/pytorch-why-do-we-need-to-set-the-gradients-manually-to-zero-in-pytorch\n",
    "# https://stackoverflow.com/questions/55735643/how-to-use-clip-grad-norm-in-pytorch\n",
    "loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=8)\n",
    "\n",
    "n_epochs = 2000\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in loader:\n",
    "        y_pred = model(X_batch)\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # Validation\n",
    "    # if epoch % 100 != 0:\n",
    "    #     continue\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_train)\n",
    "        train_rmse = np.sqrt(loss_fn(y_pred, y_train))\n",
    "        y_pred = model(X_test)\n",
    "        test_rmse = np.sqrt(loss_fn(y_pred, y_test))\n",
    "    print(\"Epoch %d: train RMSE %.4f, test RMSE %.4f\" % (epoch, train_rmse, test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "model = AirModel(input_size=62, lookback_size=lookback)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.MSELoss()\n",
    "# we need to gradient clip because the LSTM is very sensitive to exploding gradients\n",
    "# https://stackoverflow.com/questions/54716377/pytorch-why-do-we-need-to-set-the-gradients-manually-to-zero-in-pytorch\n",
    "# https://stackoverflow.com/questions/55735643/how-to-use-clip-grad-norm-in-pytorch\n",
    "loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=8)\n",
    "\n",
    "n_epochs = 2000\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in loader:\n",
    "        y_pred = model(X_batch)\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # Validation\n",
    "    # if epoch % 100 != 0:\n",
    "    #     continue\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_train)\n",
    "        train_rmse = np.sqrt(loss_fn(y_pred, y_train))\n",
    "        y_pred = model(X_test)\n",
    "        test_rmse = np.sqrt(loss_fn(y_pred, y_test))\n",
    "    print(\"Epoch %d: train RMSE %.4f, test RMSE %.4f\" % (epoch, train_rmse, test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 0: train RMSE 225961433890816.0000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we experiment with the ddos syn dataset. Unlike the darknet dataset, which was pre cleaned for a different experiment, the syn dataset has its timestamps, so it can be ordered by time. We will use this to our advantage to create a time series model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting 282982 rows with Infinity in column Flow Bytes/s\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "ddos: pd.DataFrame = remove_infs_and_nans(dataset_3)\n",
    "ddos.columns = [column.strip() for column in ddos.columns]\n",
    "\n",
    "timestamps = ddos['Timestamp']\n",
    "std_time = timestamps.apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S.%f').timestamp())\n",
    "ddos['Timestamp'] = std_time\n",
    "\n",
    "ddos = ddos.sort_values(by=['Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure pandas to show float64 with 10 decimal places\n",
    "pd.options.display.float_format = '{:.10f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_cols= [\n",
    "    'Timestamp',\n",
    "]\n",
    "\n",
    "speed_cols = [\n",
    "    'Flow Bytes/s',\n",
    "\n",
    "    'Bwd Packets/s',\n",
    "    'Fwd Packets/s',\n",
    "    'Flow Packets/s',\n",
    "    \n",
    "    'Down/Up Ratio',\n",
    "]\n",
    "\n",
    "length_cols = [\n",
    "    'ACK Flag Count',\n",
    "    'CWE Flag Count',\n",
    "    'ECE Flag Count',\n",
    "    'FIN Flag Count',\n",
    "    'PSH Flag Count',\n",
    "    'RST Flag Count',\n",
    "    'SYN Flag Count',\n",
    "    'URG Flag Count',\n",
    "    \n",
    "    'Flow Duration',\n",
    "\n",
    "    'Bwd PSH Flags',\n",
    "    'Fwd PSH Flags',\n",
    "    'Bwd URG Flags',\n",
    "    'Fwd URG Flags',\n",
    "\n",
    "    'Bwd Header Length',\n",
    "    \n",
    "    'Total Length of Fwd Packets',\n",
    "    'Total Length of Bwd Packets',\n",
    "    'Fwd Header Length',\n",
    "    \n",
    "    'Total Backward Packets',\n",
    "    'Total Fwd Packets',\n",
    "    'Subflow Bwd Packets',\n",
    "    'Subflow Fwd Packets',\n",
    "    \n",
    "    'Subflow Fwd Bytes',\n",
    "    'Subflow Bwd Bytes',\n",
    "\n",
    "    'Bwd IAT Total',\n",
    "    'Fwd IAT Total',\n",
    "\n",
    "    'act_data_pkt_fwd',\n",
    "    'Init_Win_bytes_backward',\n",
    "    'Init_Win_bytes_forward',\n",
    "]\n",
    "\n",
    "categorical_cols = {\n",
    "    'Protocol': 16,\n",
    "    'Inbound': 2,\n",
    "}\n",
    "\n",
    "min_cols = [\n",
    "    'Active Min',\n",
    "    'Idle Min',\n",
    "\n",
    "    'Bwd IAT Min',\n",
    "    'Fwd IAT Min',\n",
    "    'Flow IAT Min',\n",
    "    \n",
    "    'Bwd Packet Length Min',\n",
    "    'Fwd Packet Length Min',\n",
    "    'Min Packet Length',\n",
    "\n",
    "    'min_seg_size_forward',\n",
    "]\n",
    "\n",
    "max_cols = [\n",
    "    'Active Max',\n",
    "    'Idle Max',\n",
    "\n",
    "    'Bwd IAT Max',\n",
    "    'Fwd IAT Max',\n",
    "    'Flow IAT Max',\n",
    "    \n",
    "    'Max Packet Length',\n",
    "    'Bwd Packet Length Max',\n",
    "    'Fwd Packet Length Max',\n",
    "]\n",
    "\n",
    "mean_cols = [\n",
    "    'Active Mean',\n",
    "    'Idle Mean',\n",
    "\n",
    "    'Bwd Avg Bulk Rate',\n",
    "    'Fwd Avg Bulk Rate',\n",
    "    \n",
    "    'Bwd Avg Bytes/Bulk',\n",
    "    'Fwd Avg Bytes/Bulk',\n",
    "    \n",
    "    'Bwd IAT Mean',\n",
    "    'Fwd IAT Mean',\n",
    "    'Flow IAT Mean',\n",
    "    \n",
    "    'Packet Length Mean',\n",
    "    'Bwd Packet Length Mean',\n",
    "    'Fwd Packet Length Mean',\n",
    "    \n",
    "    'Average Packet Size',\n",
    "    'Bwd Avg Packets/Bulk',\n",
    "    'Fwd Avg Packets/Bulk',\n",
    "    \n",
    "    'Avg Bwd Segment Size',\n",
    "    'Avg Fwd Segment Size',\n",
    "]\n",
    "\n",
    "std_cols = [\n",
    "    'Active Std',\n",
    "    'Idle Std',\n",
    "    \n",
    "    'Bwd IAT Std',\n",
    "    'Fwd IAT Std',\n",
    "    'Flow IAT Std',\n",
    "\n",
    "    'Packet Length Std',\n",
    "    'Packet Length Variance',\n",
    "    'Bwd Packet Length Std',\n",
    "    'Fwd Packet Length Std',\n",
    "]\n",
    "\n",
    "port_cols = [\n",
    "    'Destination Port',\n",
    "    'Source Port',\n",
    "]\n",
    "\n",
    "unused_cols = [\n",
    "    'Unnamed: 0',\n",
    "    'Flow ID',\n",
    "    'Source IP',\n",
    "    'Destination IP',\n",
    "    'SimillarHTTP',\n",
    "    'Label',\n",
    "    'Fwd Header Length.1'\n",
    "] + port_cols\n",
    "\n",
    "# concatenate all column groups together to get a list of all columns\n",
    "all_cols = speed_cols + port_cols + length_cols + time_cols + list(categorical_cols.keys()) + min_cols + max_cols + mean_cols + std_cols + unused_cols\n",
    "\n",
    "# all_cols = time_cols + categorical_cols + min_cols + max_cols + mean_cols + std_cols + length_cols + unused_cols\n",
    "\n",
    "set(ddos.columns)- set(all_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_groups = {\n",
    "    'speed_cols': speed_cols,\n",
    "    'length_cols': length_cols,\n",
    "    'min_cols': min_cols,\n",
    "    'max_cols': max_cols,\n",
    "    'mean_cols': mean_cols,\n",
    "    'std_cols': std_cols,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddos_clean = ddos.copy().drop(columns=unused_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(ddos_clean) * 0.8)\n",
    "test_size = len(ddos_clean) - train_size\n",
    "train = ddos_clean[:train_size]\n",
    "test = ddos_clean[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    map_index_key = '__map_index__'\n",
    "    category_map = {}\n",
    "    old_maps = []\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        pipeline: List[Callable[[pd.DataFrame], pd.DataFrame]],\n",
    "        device: torch.device,\n",
    "    ) -> None:\n",
    "\n",
    "        self.pipeline = pipeline\n",
    "        self.device = device\n",
    "\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, leave_out: List[str] = ['Timestamp']):\n",
    "\n",
    "        X = X.copy()\n",
    "        for col in leave_out:\n",
    "            if col in X.columns:\n",
    "                X = X.drop(columns=[col])\n",
    "\n",
    "        for step in self.pipeline:\n",
    "            step.fit(X)\n",
    "\n",
    "        self.fitted = True\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(\n",
    "        self, \n",
    "        X: pd.DataFrame,\n",
    "        leave_out: List[str] = ['Timestamp']\n",
    "    ) -> pd.DataFrame:\n",
    "\n",
    "        if not self.fitted:\n",
    "            raise Exception('E1: You must fit the preprocessor before transforming')\n",
    "    \n",
    "        X = X.copy()\n",
    "        \n",
    "        if leave_out != []:\n",
    "            left_out = X[leave_out]\n",
    "            X = X.drop(columns=leave_out)\n",
    "\n",
    "        columns = X.columns\n",
    "\n",
    "        for col in leave_out:\n",
    "            if col in columns:\n",
    "                raise Exception('E2: Column %s was found in the transformed dataset' % col)\n",
    "\n",
    "\n",
    "        for step in self.pipeline:\n",
    "            X = step.transform(X)\n",
    "\n",
    "        X = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "        if leave_out != []:\n",
    "            for col in leave_out:\n",
    "                X[col] = left_out[col]\n",
    "            # X[leave_out] = left_out\n",
    "\n",
    "        for col in leave_out:\n",
    "            if col not in X.columns:\n",
    "                raise Exception('E3: Column %s was not found in the transformed dataset' % col)\n",
    "\n",
    "        return X\n",
    "\n",
    "    def index_categories(\n",
    "        self, \n",
    "        X: pd.DataFrame, \n",
    "        categorical_cols: List[str]\n",
    "    ) -> pd.DataFrame:\n",
    "        '''\n",
    "            We need to index the categorical columns so that they are in the range [0, n_categories) and save the mapping\n",
    "        '''\n",
    "        X = X.copy()\n",
    "\n",
    "        if self.map_index_key in categorical_cols:\n",
    "            raise Exception('Cannot use the reserved key %s as a column name' % self.map_index_key)\n",
    "\n",
    "        if self.category_map != {}:\n",
    "            self.old_maps.append(self.category_map)\n",
    "        \n",
    "        old_mapping_index = len(self.old_maps)\n",
    "\n",
    "        for col in categorical_cols:\n",
    "            X[col], self.category_map[col] = pd.factorize(X[col])\n",
    "            self.category_map[self.map_index_key] = old_mapping_index    \n",
    "\n",
    "        return X\n",
    "\n",
    "    def create_dataset(\n",
    "        self, \n",
    "        dataset: pd.DataFrame,\n",
    "        categorical_cols: List[str],\n",
    "        relative_cols: List[str],\n",
    "        other_cols: Dict[str, List[str]],\n",
    "        context_sequence_length: int = 1,\n",
    "        target_sequence_length: int = 1,\n",
    "        target_sequence_offset: int = 0,\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        '''\n",
    "            We create a dataset for each column group where each shares the same index\n",
    "            in the first dimension\n",
    "\n",
    "            This is because the groups will have different lengths in the last dimension\n",
    "            \n",
    "\n",
    "            We also need to create a context and target sequence for each column group\n",
    "                where the context sequence is the input and the target sequence is the output\n",
    "            \n",
    "                for each sample s in the dataset:\n",
    "                    context_sequence = df[s:s+context_sequence_length]\n",
    "                    target_sequence = df[s+target_sequence_offset:s+target_sequence_offset+target_sequence_length]\n",
    "\n",
    "\n",
    "        '''\n",
    "        \n",
    "        if not self.fitted:\n",
    "            self.fit(\n",
    "                dataset, \n",
    "                leave_out=relative_cols + categorical_cols\n",
    "            )\n",
    "\n",
    "        dataset = self.transform(\n",
    "            dataset,\n",
    "            leave_out=relative_cols + categorical_cols\n",
    "        )\n",
    "\n",
    "        bounds = max(\n",
    "            context_sequence_length, \n",
    "            target_sequence_length + target_sequence_offset\n",
    "        )\n",
    "\n",
    "        dataset_groups = {}\n",
    "\n",
    "        for i, (name, group) in enumerate(other_cols.items()):\n",
    "            dataset_groups[name] = dataset[group]\n",
    "\n",
    "        categorical_data = dataset[categorical_cols]\n",
    "        categorical_data = self.index_categories(categorical_data, categorical_cols)\n",
    "\n",
    "        relative_data = dataset[relative_cols]\n",
    "\n",
    "        output = {}\n",
    "\n",
    "        src = '_source'\n",
    "        tgt = '_target'\n",
    "\n",
    "        output['categorical_data' + src] = []\n",
    "        output['categorical_data' + tgt] = []\n",
    "        output['relative_data' + src] = []\n",
    "        output['relative_data' + tgt] = []\n",
    "    \n",
    "        for name in other_cols.keys():\n",
    "            output[name + src] = []\n",
    "            output[name + tgt] = []\n",
    "\n",
    "        for i in range(len(dataset) - bounds):\n",
    "            \n",
    "            output['categorical_data' + src].append(\n",
    "                categorical_data[i:i+context_sequence_length].values\n",
    "            )\n",
    "\n",
    "            output['categorical_data' + tgt].append(\n",
    "                categorical_data[i+target_sequence_offset:i+target_sequence_offset+target_sequence_length].values\n",
    "            )\n",
    "\n",
    "            relative_source = relative_data[i:i+context_sequence_length].values\n",
    "\n",
    "            relative_target = relative_data[i+target_sequence_offset:i+target_sequence_offset+target_sequence_length].values\n",
    "\n",
    "            relative_source = relative_source - relative_source[0]\n",
    "            relative_target = relative_target - relative_source[0]\n",
    "\n",
    "            output['relative_data' + src].append(\n",
    "                relative_source\n",
    "            )\n",
    "\n",
    "            output['relative_data' + tgt].append(\n",
    "                relative_target\n",
    "            )\n",
    "            \n",
    "\n",
    "            for name in dataset_groups.keys():\n",
    "                output[name + src].append(\n",
    "                    dataset_groups[name][i:i+context_sequence_length].values\n",
    "                )\n",
    "\n",
    "                output[name + tgt].append(\n",
    "                    dataset_groups[name][i+target_sequence_offset:i+target_sequence_offset+target_sequence_length].values\n",
    "                )\n",
    "\n",
    "        for name in output.keys():\n",
    "            if name == 'categorical_data' + src or name == 'categorical_data' + tgt:\n",
    "                output[name] = torch.tensor(output[name], dtype=torch.long, device=self.device)\n",
    "            else:\n",
    "                output[name] = torch.tensor(output[name], dtype=torch.float32, device=self.device)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical_data_source torch.Size([989, 10, 2])\n",
      "categorical_data_target torch.Size([989, 3, 2])\n",
      "relative_data_source torch.Size([989, 10, 1])\n",
      "relative_data_target torch.Size([989, 3, 1])\n",
      "speed_cols_source torch.Size([989, 10, 5])\n",
      "speed_cols_target torch.Size([989, 3, 5])\n",
      "length_cols_source torch.Size([989, 10, 28])\n",
      "length_cols_target torch.Size([989, 3, 28])\n",
      "min_cols_source torch.Size([989, 10, 9])\n",
      "min_cols_target torch.Size([989, 3, 9])\n",
      "max_cols_source torch.Size([989, 10, 8])\n",
      "max_cols_target torch.Size([989, 3, 8])\n",
      "mean_cols_source torch.Size([989, 10, 17])\n",
      "mean_cols_target torch.Size([989, 3, 17])\n",
      "std_cols_source torch.Size([989, 10, 9])\n",
      "std_cols_target torch.Size([989, 3, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gc/jb6dhmdd3r37x6bvx8rw9w980000gn/T/ipykernel_90210/1148857516.py:197: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1682343686209/work/torch/csrc/utils/tensor_new.cpp:248.)\n",
      "  output[name] = torch.tensor(output[name], dtype=torch.long, device=self.device)\n"
     ]
    }
   ],
   "source": [
    "time_cols= [\n",
    "    'Timestamp',\n",
    "]\n",
    "\n",
    "speed_cols = [\n",
    "    'Flow Bytes/s',\n",
    "\n",
    "    'Bwd Packets/s',\n",
    "    'Fwd Packets/s',\n",
    "    'Flow Packets/s',\n",
    "    \n",
    "    'Down/Up Ratio',\n",
    "]\n",
    "\n",
    "length_cols = [\n",
    "    'ACK Flag Count',\n",
    "    'CWE Flag Count',\n",
    "    'ECE Flag Count',\n",
    "    'FIN Flag Count',\n",
    "    'PSH Flag Count',\n",
    "    'RST Flag Count',\n",
    "    'SYN Flag Count',\n",
    "    'URG Flag Count',\n",
    "    \n",
    "    'Flow Duration',\n",
    "\n",
    "    'Bwd PSH Flags',\n",
    "    'Fwd PSH Flags',\n",
    "    'Bwd URG Flags',\n",
    "    'Fwd URG Flags',\n",
    "\n",
    "    'Bwd Header Length',\n",
    "    \n",
    "    'Total Length of Fwd Packets',\n",
    "    'Total Length of Bwd Packets',\n",
    "    'Fwd Header Length',\n",
    "    \n",
    "    'Total Backward Packets',\n",
    "    'Total Fwd Packets',\n",
    "    'Subflow Bwd Packets',\n",
    "    'Subflow Fwd Packets',\n",
    "    \n",
    "    'Subflow Fwd Bytes',\n",
    "    'Subflow Bwd Bytes',\n",
    "\n",
    "    'Bwd IAT Total',\n",
    "    'Fwd IAT Total',\n",
    "\n",
    "    'act_data_pkt_fwd',\n",
    "    'Init_Win_bytes_backward',\n",
    "    'Init_Win_bytes_forward',\n",
    "]\n",
    "\n",
    "min_cols = [\n",
    "    'Active Min',\n",
    "    'Idle Min',\n",
    "\n",
    "    'Bwd IAT Min',\n",
    "    'Fwd IAT Min',\n",
    "    'Flow IAT Min',\n",
    "    \n",
    "    'Bwd Packet Length Min',\n",
    "    'Fwd Packet Length Min',\n",
    "    'Min Packet Length',\n",
    "\n",
    "    'min_seg_size_forward',\n",
    "]\n",
    "\n",
    "max_cols = [\n",
    "    'Active Max',\n",
    "    'Idle Max',\n",
    "\n",
    "    'Bwd IAT Max',\n",
    "    'Fwd IAT Max',\n",
    "    'Flow IAT Max',\n",
    "    \n",
    "    'Max Packet Length',\n",
    "    'Bwd Packet Length Max',\n",
    "    'Fwd Packet Length Max',\n",
    "]\n",
    "\n",
    "mean_cols = [\n",
    "    'Active Mean',\n",
    "    'Idle Mean',\n",
    "\n",
    "    'Bwd Avg Bulk Rate',\n",
    "    'Fwd Avg Bulk Rate',\n",
    "    \n",
    "    'Bwd Avg Bytes/Bulk',\n",
    "    'Fwd Avg Bytes/Bulk',\n",
    "    \n",
    "    'Bwd IAT Mean',\n",
    "    'Fwd IAT Mean',\n",
    "    'Flow IAT Mean',\n",
    "    \n",
    "    'Packet Length Mean',\n",
    "    'Bwd Packet Length Mean',\n",
    "    'Fwd Packet Length Mean',\n",
    "    \n",
    "    'Average Packet Size',\n",
    "    'Bwd Avg Packets/Bulk',\n",
    "    'Fwd Avg Packets/Bulk',\n",
    "    \n",
    "    'Avg Bwd Segment Size',\n",
    "    'Avg Fwd Segment Size',\n",
    "]\n",
    "\n",
    "std_cols = [\n",
    "    'Active Std',\n",
    "    'Idle Std',\n",
    "    \n",
    "    'Bwd IAT Std',\n",
    "    'Fwd IAT Std',\n",
    "    'Flow IAT Std',\n",
    "\n",
    "    'Packet Length Std',\n",
    "    'Packet Length Variance',\n",
    "    'Bwd Packet Length Std',\n",
    "    'Fwd Packet Length Std',\n",
    "]\n",
    "\n",
    "column_groups = {\n",
    "    'speed_cols': speed_cols,\n",
    "    'length_cols': length_cols,\n",
    "    'min_cols': min_cols,\n",
    "    'max_cols': max_cols,\n",
    "    'mean_cols': mean_cols,\n",
    "    'std_cols': std_cols,\n",
    "}\n",
    "\n",
    "categorical_cols = {\n",
    "        'Protocol': 16,\n",
    "        'Inbound': 2,\n",
    "}\n",
    "\n",
    "process = Preprocessor([StandardScaler()], device)\n",
    "\n",
    "context_length = 10\n",
    "target_length = 3\n",
    "target_offset = 8\n",
    "\n",
    "data_dict = process.create_dataset(\n",
    "    ddos_clean[:1000],\n",
    "    list(categorical_cols.keys()),\n",
    "    time_cols,\n",
    "    column_groups,\n",
    "    context_sequence_length=context_length,\n",
    "    target_sequence_length=target_length,\n",
    "    target_sequence_offset=target_offset\n",
    ")\n",
    "\n",
    "for name, tensor in data_dict.items():\n",
    "    print(name, tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_dataset = data.TensorDataset(\n",
    "    data_dict['relative_data_source'],\n",
    "    data_dict['categorical_data_source'],\n",
    "    data_dict['speed_cols_source'],\n",
    "    data_dict['length_cols_source'],\n",
    "    data_dict['min_cols_source'],\n",
    "    data_dict['max_cols_source'],\n",
    "    data_dict['mean_cols_source'],\n",
    "    data_dict['std_cols_source'],\n",
    "    data_dict['relative_data_target'],\n",
    "    data_dict['categorical_data_target'],\n",
    "    data_dict['speed_cols_target'],\n",
    "    data_dict['length_cols_target'],\n",
    "    data_dict['min_cols_target'],\n",
    "    data_dict['max_cols_target'],\n",
    "    data_dict['mean_cols_target'],\n",
    "    data_dict['std_cols_target'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_size = int(len(tensor_dataset) * 0.8)\n",
    "test_size = len(tensor_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(tensor_dataset, [train_size, test_size])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = data.DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "test_dataloader = data.DataLoader(test_dataset, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratedLoss(nn.Module):\n",
    "    \"Measures how well we have generated the sequence item\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        categorical_cols\n",
    "    ):\n",
    "        super(GeneratedLoss, self).__init__()\n",
    "\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "        self.categorical_cols = categorical_cols\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        preds, \n",
    "        cat_targs, \n",
    "        cont_targs\n",
    "    ):\n",
    "\n",
    "        cats, conts = preds\n",
    "        tot_ce, pos = cats.new([0]), 0\n",
    "        for i, (k,v) in enumerate(self.cat_dict.items()):\n",
    "            tot_ce += self.ce(cats[:, pos:pos+v], cat_targs[:,i])\n",
    "            pos += v\n",
    "        \n",
    "        norm_cats = cats.new([len(self.cat_dict)])\n",
    "        norm_conts = conts.new([conts.size(1)])\n",
    "        cat_loss = tot_ce/norm_cats\n",
    "        cont_loss = self.mse(conts, cont_targs)/norm_conts\n",
    "        total = cat_loss+cont_loss\n",
    "\n",
    "        return total / cats.size(0)\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size     : int,\n",
    "        heads              : int,\n",
    "        device             : torch.device,\n",
    "    ) -> None:\n",
    "    \n",
    "        super(MultiheadAttention, self).__init__()\n",
    "\n",
    "        self.embedding_size      = embedding_size\n",
    "        self.heads               = heads\n",
    "\n",
    "        if embedding_size % heads != 0:\n",
    "            raise Exception(f'embedding_size must be divisible by heads. embedding_size: {embedding_size}, heads: {heads}')\n",
    "\n",
    "        self.query = nn.Linear(embedding_size, embedding_size, device = device)\n",
    "        self.key   = nn.Linear(embedding_size, embedding_size, device = device)\n",
    "        self.value = nn.Linear(embedding_size, embedding_size, device = device)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        q: torch.Tensor, \n",
    "        v: torch.Tensor,\n",
    "        k: torch.Tensor\n",
    "    ):\n",
    "        '''\n",
    "            We perform multihead attention on the query embeddings using the encoder state as the key and value\n",
    "\n",
    "            shape:\n",
    "                x: (batch_size, total_num_queries, embedding_size)\n",
    "                encoder_state: (batch_size, lookback_size, embedding_size)\n",
    "                output: (batch_size, total_num_queries, embedding_size)\n",
    "        '''\n",
    "\n",
    "        # print(f\"q: {q.shape}\")\n",
    "\n",
    "        key  : torch.Tensor = self.key(k)\n",
    "        value: torch.Tensor = self.value(v)\n",
    "        query: torch.Tensor = self.query(q)\n",
    "\n",
    "        # we split the query, key, and value into heads\n",
    "        query = query.reshape(\n",
    "            query.shape[0],\n",
    "            query.shape[1],\n",
    "            self.heads,\n",
    "            self.embedding_size // self.heads\n",
    "        ).transpose(1, 2)\n",
    "\n",
    "        key = key.reshape(\n",
    "            key.shape[0],\n",
    "            key.shape[1],\n",
    "            self.heads,\n",
    "            self.embedding_size // self.heads\n",
    "        ).transpose(1, 2)\n",
    "\n",
    "        value = value.reshape(\n",
    "            value.shape[0],\n",
    "            value.shape[1],\n",
    "            self.heads,\n",
    "            self.embedding_size // self.heads\n",
    "        ).transpose(1, 2)\n",
    "\n",
    "        # we perform the attention\n",
    "        pre_attention = torch.matmul(query, key.transpose(-2, -1))/torch.sqrt(torch.tensor(self.embedding_size, dtype=torch.float32))\n",
    "\n",
    "        # print(f\"pre_attention: {pre_attention.shape}\")\n",
    "\n",
    "        # we apply the softmax to the pre_attention\n",
    "\n",
    "        distribution = self.softmax(pre_attention)\n",
    "\n",
    "        # print(f\"distribution: {distribution.shape}\")\n",
    "        # print(f\"value: {value.shape}\")\n",
    "\n",
    "        attention = torch.einsum('bhqk,bhkd->bhqd', distribution, value)\n",
    "\n",
    "        # attention = torch.matmul(self.softmax(pre_attention), value)\n",
    "\n",
    "        # print(f\"attention: {attention.shape}\")\n",
    "\n",
    "\n",
    "        # attention shape: batch_size, heads, total_num_queries, embedding_size // heads\n",
    "        # final shape: batch_size, total_num_queries, embedding_size\n",
    "\n",
    "        full_attention = attention.transpose(1, 2).reshape(\n",
    "            attention.shape[0],\n",
    "            attention.shape[-2],\n",
    "            self.embedding_size\n",
    "        )\n",
    "\n",
    "        # print(f\"full_attention: {full_attention.shape}\")\n",
    "\n",
    "        return full_attention\n",
    "\n",
    "class RandomFourierTimeEncoding(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        device: torch.device,\n",
    "        input_size: int = 1,\n",
    "        encoding_half_size: int = 50,\n",
    "        sigma: float = 4,\n",
    "    ) -> None:\n",
    "        super(RandomFourierTimeEncoding, self).__init__()\n",
    "\n",
    "        self.fourier = GaussianEncoding(\n",
    "            sigma=sigma,\n",
    "            input_size=input_size,\n",
    "            encoded_size=encoding_half_size,\n",
    "        ).to(device)\n",
    "        # )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        X: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        '''\n",
    "            X: (batch_size, sequence_length, input_size)\n",
    "            output: (batch_size, sequence_length, 2*encoding_half_size + input_size)\n",
    "        '''\n",
    "\n",
    "        output = self.fourier(X)\n",
    "        output = torch.cat([X, output], dim=-1)\n",
    "\n",
    "        return output\n",
    "\n",
    "class TrafficFlowEncoderBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size: int,\n",
    "        heads: int,\n",
    "        forward_expansion: int,\n",
    "        device: torch.device,\n",
    "        dropout_rate: float = 0.1,\n",
    "    ) -> None:\n",
    "        super(TrafficFlowEncoderBlock, self).__init__()\n",
    "\n",
    "        self.attention = MultiheadAttention(\n",
    "            embedding_size=embedding_size,\n",
    "            heads=heads,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(embedding_size)\n",
    "        self.norm2 = nn.LayerNorm(embedding_size)\n",
    "\n",
    "        self.ffw = nn.Sequential(\n",
    "            nn.Linear(embedding_size, forward_expansion*embedding_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(forward_expansion*embedding_size, embedding_size),\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        X: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        '''\n",
    "            X: (batch_size, sequence_length, embedding_size)\n",
    "            output: (batch_size, sequence_length, embedding_size)\n",
    "        '''\n",
    "\n",
    "        X_norm = self.norm1(X)\n",
    "\n",
    "        attention = self.attention(X_norm, X_norm, X_norm)\n",
    "\n",
    "        X = X + self.dropout(attention)\n",
    "\n",
    "        X_norm = self.norm2(X)\n",
    "\n",
    "        ffw = self.ffw(X_norm)\n",
    "\n",
    "        X = X + self.dropout(ffw)\n",
    "\n",
    "        return X\n",
    "\n",
    "class TrafficFlowEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size: int,\n",
    "        heads: int,\n",
    "        forward_expansion: int,\n",
    "        num_layers: int,\n",
    "        device: torch.device,\n",
    "        dropout_rate: float = 0.1,\n",
    "    ) -> None:\n",
    "        super(TrafficFlowEncoder, self).__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            *[TrafficFlowEncoderBlock(\n",
    "                embedding_size=embedding_size,\n",
    "                heads=heads,\n",
    "                forward_expansion=forward_expansion,\n",
    "                device=device,\n",
    "                dropout_rate=dropout_rate,\n",
    "            ) for _ in range(num_layers)]\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        X: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        '''\n",
    "            X: (batch_size, sequence_length, embedding_size)\n",
    "            output: (batch_size, sequence_length, embedding_size)\n",
    "        '''\n",
    "\n",
    "        return self.layers(X)\n",
    "\n",
    "\n",
    "\n",
    "class TrafficFlowTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        categorical_cols: Dict[str, int],\n",
    "        column_groups: Dict[str, List[str]],\n",
    "        device: torch.device,\n",
    "        embedding_size: int = 100,\n",
    "        encoding_size: int = 50,\n",
    "        encoder_heads: int = 2,\n",
    "        encoder_layers: int = 2,\n",
    "        encoder_forward_expansion: int = 2,\n",
    "    ) -> None:\n",
    "    \n",
    "        super(TrafficFlowTransformer, self).__init__()\n",
    "    \n",
    "        self.categorical_cols = categorical_cols\n",
    "\n",
    "        self.time_embedding = nn.Sequential(\n",
    "            RandomFourierTimeEncoding(\n",
    "                device=device,\n",
    "                input_size=1,\n",
    "                encoding_half_size=encoding_size,\n",
    "            ),\n",
    "            nn.Linear(2*encoding_size + 1, embedding_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_size, embedding_size),\n",
    "        ).to(device)\n",
    "\n",
    "        self.categorical_embeddings = nn.ModuleDict({\n",
    "            col: nn.Embedding(num_embeddings=n_categories, embedding_dim=embedding_size)\n",
    "            for col, n_categories in categorical_cols.items()\n",
    "        }).to(device)\n",
    "\n",
    "        self.continuous_embeddings = nn.ModuleDict({\n",
    "            group: nn.Sequential(\n",
    "                nn.Linear(len(cols), embedding_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(embedding_size, embedding_size),\n",
    "            ) for group, cols in column_groups.items()\n",
    "        }).to(device)\n",
    "\n",
    "        self.encoder = TrafficFlowEncoder(\n",
    "            embedding_size=embedding_size,\n",
    "            heads=encoder_heads,\n",
    "            forward_expansion=encoder_forward_expansion,\n",
    "            num_layers=encoder_layers,\n",
    "            device=device,\n",
    "        ).to(device)\n",
    "\n",
    "        # self.transformer = nn.Transformer(\n",
    "        #     d_model=embedding_size,\n",
    "        #     nhead=encoder_heads,\n",
    "        #     num_encoder_layers=encoder_layers,\n",
    "        #     num_decoder_layers=decoder_layers,\n",
    "        #     dim_feedforward=encoder_forward_expansion*embedding_size,\n",
    "        #     dropout=dropout_rate,\n",
    "        # ).to(device)\n",
    "\n",
    "        # self.encoder = self.transformer.encoder\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        X_time,\n",
    "        X_cat,\n",
    "        X_cont_group,\n",
    "        y_time\n",
    "    ):\n",
    "        print(f\"X_time: {X_time.shape}\")\n",
    "        print(f\"X_cat: {X_cat.shape}\")\n",
    "        # print(f\"X_cont_group: {X_cont_group.shape}\")\n",
    "        print(f\"X_cont_group: {len(X_cont_group)}\")\n",
    "        print(f\"y_time: {y_time.shape}\")\n",
    "\n",
    "        # we embed the time\n",
    "        X_time_emb = self.time_embedding(X_time)\n",
    "        Y_time_emb = self.time_embedding(y_time)\n",
    "\n",
    "        print(f\"X_time_emb: {X_time_emb.shape}\")\n",
    "        print(f\"y_time_emb: {Y_time_emb.shape}\")\n",
    "\n",
    "        # we embed the categorical columns\n",
    "        X_cat_embs = [\n",
    "            self.categorical_embeddings[col](X_cat[:, :, i])\n",
    "            for i, col in enumerate(self.categorical_cols.keys())\n",
    "        ]\n",
    "\n",
    "        print(*[f\"X_cat_embs[{i}]: {emb.shape}\" for i, emb in enumerate(X_cat_embs)], sep='\\n')\n",
    "\n",
    "        # we embed the continuous columns\n",
    "        X_cont_embs = [\n",
    "            self.continuous_embeddings[group](X_cont_group[group])\n",
    "            for group in self.continuous_embeddings.keys()\n",
    "        ]\n",
    "\n",
    "        print(*[f\"X_cont_embs[{i}]: {emb.shape}\" for i, emb in enumerate(X_cont_embs)], sep='\\n')\n",
    "\n",
    "        # print(f\"X_cat_embs: {[emb.shape for emb in X_cat_embs]}\")\n",
    "        # print(f\"X_cont_embs: {[emb.shape for emb in X_cont_embs]}\")\n",
    "\n",
    "        X_emb = X_time_emb + sum(X_cat_embs) + sum(X_cont_embs)\n",
    "\n",
    "        print(f\"X_emb: {X_emb.shape}\")\n",
    "\n",
    "        X_enc = self.encoder(X_emb)\n",
    "\n",
    "        print(f\"X_enc: {X_enc.shape}\")\n",
    "\n",
    "        X_fourier = torch.fft.fft(X_enc, dim=-1)\n",
    "\n",
    "        print(f\"X_fourier: {X_fourier.shape}\")\n",
    "\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_time: torch.Size([64, 10, 1])\n",
      "X_cat: torch.Size([64, 10, 2])\n",
      "X_cont_group: 6\n",
      "y_time: torch.Size([64, 3, 1])\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "X_time_emb: torch.Size([64, 10, 100])\n",
      "y_time_emb: torch.Size([64, 3, 100])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 56\u001b[0m\n\u001b[1;32m     51\u001b[0m X_cont_group_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     52\u001b[0m     group: X_cont_group[i] \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(column_groups\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m     53\u001b[0m }\n\u001b[1;32m     54\u001b[0m y_cont_group \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m10\u001b[39m:]\n\u001b[0;32m---> 56\u001b[0m y_cat_pred, y_cont_group \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_cat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_cont_group_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m batch_0 \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fast_gpu/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[15], line 334\u001b[0m, in \u001b[0;36mTrafficFlowTransformer.forward\u001b[0;34m(self, X_time, X_cat, X_cont_group, y_time)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_time_emb: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY_time_emb\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    333\u001b[0m \u001b[38;5;66;03m# we embed the categorical columns\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m X_cat_embs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategorical_embeddings[col](X_cat[:, :, i])\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategorical_cols\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m    337\u001b[0m ]\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m*\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_cat_embs[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00memb\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, emb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(X_cat_embs)], sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# we embed the continuous columns\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 335\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_time_emb: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY_time_emb\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    333\u001b[0m \u001b[38;5;66;03m# we embed the categorical columns\u001b[39;00m\n\u001b[1;32m    334\u001b[0m X_cat_embs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 335\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_embeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_cat\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategorical_cols\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m    337\u001b[0m ]\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m*\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_cat_embs[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00memb\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, emb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(X_cat_embs)], sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# we embed the continuous columns\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fast_gpu/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fast_gpu/lib/python3.9/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    163\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    164\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fast_gpu/lib/python3.9/site-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "\n",
    "n_epochs = 10\n",
    "\n",
    "column_groups = {\n",
    "    'speed_cols': speed_cols,\n",
    "    'length_cols': length_cols,\n",
    "    'min_cols': min_cols,\n",
    "    'max_cols': max_cols,\n",
    "    'mean_cols': mean_cols,\n",
    "    'std_cols': std_cols,\n",
    "}\n",
    "\n",
    "categorical_cols = {\n",
    "        'Protocol': 16,\n",
    "        'Inbound': 2,\n",
    "}\n",
    "\n",
    "epoch_length = len(train_dataloader.dataset)\n",
    "\n",
    "train_losses = []\n",
    "test_losses  = []\n",
    "train_counter = []\n",
    "test_counter = [i*epoch_length for i in range(n_epochs + 1)]\n",
    "\n",
    "\n",
    "loss_fn = GeneratedLoss(\n",
    "    categorical_cols\n",
    ")\n",
    "\n",
    "batch_0 = None\n",
    "\n",
    "model = TrafficFlowTransformer(\n",
    "    categorical_cols,\n",
    "    column_groups,\n",
    "    embedding_size=100,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# print(model)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        X_time = batch[0]\n",
    "        y_time = batch[8]\n",
    "\n",
    "        X_cat = batch[1]\n",
    "        y_cat = batch[9]\n",
    "\n",
    "        X_cont_group = batch[2:8]\n",
    "        X_cont_group_dict = {\n",
    "            group: X_cont_group[i] for i, group in enumerate(column_groups.keys())\n",
    "        }\n",
    "        y_cont_group = batch[10:]\n",
    "\n",
    "        y_cat_pred, y_cont_group = model(\n",
    "            X_time,\n",
    "            X_cat,\n",
    "            X_cont_group_dict,\n",
    "            y_time,\n",
    "        )\n",
    "\n",
    "        batch_0 = batch\n",
    "        break\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import (\n",
    "    Dict,\n",
    "    List\n",
    ")\n",
    "\n",
    "class DebugLayer(nn.Module):\n",
    "    '''\n",
    "        This module is simply an intermediate that will print out the shape of the input\n",
    "    '''\n",
    "    def __init__(self) -> None:\n",
    "        super(DebugLayer, self).__init__()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, verbose: bool = False) -> torch.Tensor:\n",
    "        if verbose:\n",
    "            print(x.shape)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficDecoderHead(nn.Module):\n",
    "    '''\n",
    "        This is the head of the decoder.\n",
    "\n",
    "        params:\n",
    "            input_size: the size of the last dimension of the input\n",
    "            categorical_cols: a dictionary of column names and the number of categories in each column\n",
    "            column_groups: a dictionary of column groups, each with a group name a list of column names\n",
    "            \n",
    "\n",
    "        For each categorical column, we create a classification trunk of layers that will end in a softmax layer of size num_categories\n",
    "        For each column group, we create a regression trunk of layers that will end in a linear layer that is the length of the column group\n",
    "    '''\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_size: int, \n",
    "        categorical_cols: Dict[str, int],\n",
    "        column_groups: Dict[str, List[str]],\n",
    "        device: torch.device,\n",
    "    ) -> None:\n",
    "    \n",
    "        super(TrafficDecoderHead, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.categorical_cols = categorical_cols\n",
    "        self.column_groups = column_groups\n",
    "        self.device = device\n",
    "\n",
    "        self.categorical_head = nn.ModuleDict()\n",
    "\n",
    "        for column, num_categories in categorical_cols.items():\n",
    "            hidden_size = (input_size + num_categories) // 2\n",
    "            self.categorical_head[column] = nn.Sequential(\n",
    "                nn.Linear(input_size, hidden_size, device = device),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_size, num_categories, device = device),\n",
    "                nn.Softmax(dim=-1)\n",
    "            )\n",
    "\n",
    "        self.continuous_head = nn.ModuleDict()\n",
    "\n",
    "        for column_group, columns in column_groups.items():\n",
    "            hidden_size = (input_size + len(columns)) // 2\n",
    "            self.continuous_head[column_group] = nn.Sequential(\n",
    "                nn.Linear(input_size, hidden_size, device = device),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_size, len(columns), device = device),\n",
    "            )\n",
    "\n",
    "        self.inspector = DebugLayer()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.inspector(x)\n",
    "\n",
    "        cont_output = torch.cat(\n",
    "            [head(x) for head in self.continuous_head.values()],\n",
    "            dim= -1\n",
    "        )\n",
    "\n",
    "        cat_output = torch.cat(\n",
    "            [head(x) for head in self.categorical_head.values()],\n",
    "            dim= -1\n",
    "        )\n",
    "\n",
    "        return cont_output, cat_output\n",
    "\n",
    "\n",
    "batch_size: int = 3\n",
    "samples: int    = 4\n",
    "variables: int  = 5\n",
    "\n",
    "column_groups = {\n",
    "    'sample_group_1':[\n",
    "        'col_1',\n",
    "        'col_2',\n",
    "    ],\n",
    "    'sample_group_2': [\n",
    "        'col_3',\n",
    "        'col_4',\n",
    "        'col_5',\n",
    "    ],\n",
    "}\n",
    "\n",
    "categorical_columns = {\n",
    "    'cat_1': 2,\n",
    "    'cat_2': 3,\n",
    "}\n",
    "\n",
    "test_vals = torch.rand(batch_size, samples, variables)\n",
    "\n",
    "\n",
    "model = TrafficDecoderHead(variables, categorical_columns, column_groups)\n",
    "# torch.onnx.export(model, test_vals, 'test.onnx', input_names=['decoder hidden state'], output_names=['decoder output'])\n",
    "model(test_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class AirModel(nn.Module):\n",
    "    def __init__(self, input_size, lookback_size, device, embedding_size=200):\n",
    "        super().__init__()\n",
    "        # self.lstm = nn.LSTM(input_size=input_size, hidden_size=embedding_size, num_layers=1, batch_first=True)\n",
    "        self.embedding_size = embedding_size\n",
    "        self.flat = nn.Flatten()\n",
    "        self.unflat = nn.Unflatten(0, (-1, 1))\n",
    "        self.cont_embed = nn.Sequential(\n",
    "            nn.Flatten(0, 1),\n",
    "            nn.Linear(input_size, embedding_size, device = device),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(embedding_size, embedding_size),\n",
    "            nn.Unflatten(0, (-1, lookback_size))\n",
    "        )\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        # we need a regression head to predict the next item in the sequence of shape \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(lookback*embedding_size, lookback*embedding_size, device = device),\n",
    "            # nn.BatchNorm1d(lookback_size*embedding_size),\n",
    "            # nn.LayerNorm(lookback*embedding_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(lookback*embedding_size, lookback*embedding_size, device = device),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(lookback*embedding_size, input_size, device = device),\n",
    "            # nn.ReLU(),\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm((lookback_size, embedding_size), device = device)\n",
    "\n",
    "        self.query = nn.Linear(embedding_size, embedding_size, device = device)\n",
    "        self.key = nn.Linear(embedding_size, embedding_size, device = device)\n",
    "        self.value = nn.Linear(embedding_size, embedding_size, device = device)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.norm2 = nn.LayerNorm(embedding_size, device = device)\n",
    "        self.norm3 = nn.LayerNorm(embedding_size, device = device)\n",
    "\n",
    "        \n",
    "\n",
    "        self.pos_embed = nn.Embedding(lookback_size, embedding_size, device = device)\n",
    "        # self.linear = nn.Linear(lookback*embedding_size, input_size)\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        # x = self.cont_embed(x)\n",
    "        x = self.cont_embed(x) + self.pos_embed(torch.arange(x.shape[1], device = self.device))\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        query = self.query(x)\n",
    "        key = self.key(x)\n",
    "        value = self.value(x)\n",
    "\n",
    "        # print(query.shape, key.shape, value.shape)\n",
    "\n",
    "        pre_attention = self.softmax(torch.matmul(query, key.transpose(-2, -1))/torch.sqrt(torch.tensor(self.embedding_size, dtype=torch.float32)))\n",
    "        \n",
    "        # print(pre_attention.shape)\n",
    "\n",
    "        attention = torch.matmul(pre_attention, value)\n",
    "        # print(attention.shape)\n",
    "\n",
    "        x = self.norm2(x + attention)\n",
    "\n",
    "        # print(x.shape)\n",
    "\n",
    "        # we mix the signals together\n",
    "        x = self.flat(x)\n",
    "        x = self.head(x)\n",
    "        x = self.unflat(x)\n",
    "\n",
    "        # print(x.shape)\n",
    "\n",
    "        # print('stopping')\n",
    "        # raise Exception('stop')\n",
    "        return x\n",
    "\n",
    "\n",
    "# model = AirModel(input_size=62, lookback_size=lookback, device = device)\n",
    "# y_pred = model(X_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size     : int,\n",
    "        heads              : int,\n",
    "        forward_expansion  : int,\n",
    "        device             : torch.device,\n",
    "    ) -> None:\n",
    "    \n",
    "        super(MultiheadAttention, self).__init__()\n",
    "\n",
    "        self.embedding_size      = embedding_size\n",
    "        self.heads               = heads\n",
    "\n",
    "        if embedding_size % heads != 0:\n",
    "            raise Exception(f'embedding_size must be divisible by heads. embedding_size: {embedding_size}, heads: {heads}')\n",
    "\n",
    "        self.query = nn.Linear(embedding_size, embedding_size, device = device)\n",
    "        self.key   = nn.Linear(embedding_size, embedding_size, device = device)\n",
    "        self.value = nn.Linear(embedding_size, embedding_size, device = device)\n",
    "\n",
    "        self.norm_1 = nn.LayerNorm(embedding_size, device = device)\n",
    "        self.norm_2 = nn.LayerNorm(embedding_size, device = device)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "        self.ffwd = nn.Sequential(\n",
    "            nn.Linear(embedding_size, forward_expansion*embedding_size, device = device),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(forward_expansion*embedding_size, embedding_size, device = device),\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        q: torch.Tensor, \n",
    "        v: torch.Tensor,\n",
    "        k: torch.Tensor\n",
    "    ):\n",
    "        '''\n",
    "            We perform multihead attention on the query embeddings using the encoder state as the key and value\n",
    "\n",
    "            shape:\n",
    "                x: (batch_size, total_num_queries, embedding_size)\n",
    "                encoder_state: (batch_size, lookback_size, embedding_size)\n",
    "                output: (batch_size, total_num_queries, embedding_size)\n",
    "        '''\n",
    "\n",
    "        key  : torch.Tensor = self.key(k)\n",
    "        value: torch.Tensor = self.value(v)\n",
    "        query: torch.Tensor = self.query(q)\n",
    "\n",
    "        # we split the query, key, and value into heads\n",
    "        query = query.reshape(\n",
    "            query.shape[0],\n",
    "            query.shape[1],\n",
    "            self.heads,\n",
    "            self.embedding_size // self.heads\n",
    "        ).transpose(1, 2)\n",
    "\n",
    "        key = key.reshape(\n",
    "            key.shape[0],\n",
    "            key.shape[1],\n",
    "            self.heads,\n",
    "            self.embedding_size // self.heads\n",
    "        ).transpose(1, 2)\n",
    "\n",
    "        value = value.reshape(\n",
    "            value.shape[0],\n",
    "            value.shape[1],\n",
    "            self.heads,\n",
    "            self.embedding_size // self.heads\n",
    "        ).transpose(1, 2)\n",
    "\n",
    "        # we perform the attention\n",
    "        pre_attention = torch.matmul(query, key.transpose(-2, -1))/torch.sqrt(torch.tensor(self.embedding_size, dtype=torch.float32))\n",
    "        attention = torch.matmul(self.softmax(pre_attention), value)\n",
    "\n",
    "        # we concatenate the heads together\n",
    "        attention = attention.transpose(1, 2).reshape(\n",
    "            attention.shape[0],\n",
    "            attention.shape[1],\n",
    "            self.embedding_size\n",
    "        )\n",
    "\n",
    "        # we pass the attention through a normalization layer\n",
    "        x = self.norm_1(attention + q)\n",
    "\n",
    "        # we pass the attention through a feed forward layer\n",
    "        x = self.norm_2(self.ffwd(x) + x)\n",
    "\n",
    "        return x\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficForecaster(nn.Module):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super(TrafficForecaster, self).__init__(*args, **kwargs)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_cols= [\n",
    "    'Timestamp',\n",
    "]\n",
    "\n",
    "speed_cols = [\n",
    "    'Flow Bytes/s',\n",
    "\n",
    "    'Bwd Packets/s',\n",
    "    'Fwd Packets/s',\n",
    "    'Flow Packets/s',\n",
    "    \n",
    "    'Down/Up Ratio',\n",
    "]\n",
    "\n",
    "port_cols = [\n",
    "    'Destination Port',\n",
    "    'Source Port',\n",
    "]\n",
    "\n",
    "length_cols = [\n",
    "    'ACK Flag Count',\n",
    "    'CWE Flag Count',\n",
    "    'ECE Flag Count',\n",
    "    'FIN Flag Count',\n",
    "    'PSH Flag Count',\n",
    "    'RST Flag Count',\n",
    "    'SYN Flag Count',\n",
    "    'URG Flag Count',\n",
    "    \n",
    "    'Flow Duration',\n",
    "\n",
    "    'Bwd PSH Flags',\n",
    "    'Fwd PSH Flags',\n",
    "    'Bwd URG Flags',\n",
    "    'Fwd URG Flags',\n",
    "\n",
    "    'Bwd Header Length',\n",
    "    \n",
    "    'Total Length of Fwd Packets',\n",
    "    'Total Length of Bwd Packets',\n",
    "    'Fwd Header Length',\n",
    "    \n",
    "    'Total Backward Packets',\n",
    "    'Total Fwd Packets',\n",
    "    'Subflow Bwd Packets',\n",
    "    'Subflow Fwd Packets',\n",
    "    \n",
    "    'Subflow Fwd Bytes',\n",
    "    'Subflow Bwd Bytes',\n",
    "\n",
    "    'Bwd IAT Total',\n",
    "    'Fwd IAT Total',\n",
    "\n",
    "    'act_data_pkt_fwd',\n",
    "    'Init_Win_bytes_backward',\n",
    "    'Init_Win_bytes_forward',\n",
    "]\n",
    "\n",
    "categorical_cols = [\n",
    "    'Protocol',\n",
    "    'Inbound',\n",
    "]\n",
    "\n",
    "min_cols = [\n",
    "    'Active Min',\n",
    "    'Idle Min',\n",
    "\n",
    "    'Bwd IAT Min',\n",
    "    'Fwd IAT Min',\n",
    "    'Flow IAT Min',\n",
    "    \n",
    "    'Bwd Packet Length Min',\n",
    "    'Fwd Packet Length Min',\n",
    "    'Min Packet Length',\n",
    "\n",
    "    'min_seg_size_forward',\n",
    "]\n",
    "\n",
    "max_cols = [\n",
    "    'Active Max',\n",
    "    'Idle Max',\n",
    "\n",
    "    'Bwd IAT Max',\n",
    "    'Fwd IAT Max',\n",
    "    'Flow IAT Max',\n",
    "    \n",
    "    'Max Packet Length',\n",
    "    'Bwd Packet Length Max',\n",
    "    'Fwd Packet Length Max',\n",
    "]\n",
    "\n",
    "mean_cols = [\n",
    "    'Active Mean',\n",
    "    'Idle Mean',\n",
    "\n",
    "    'Bwd Avg Bulk Rate',\n",
    "    'Fwd Avg Bulk Rate',\n",
    "    \n",
    "    'Bwd Avg Bytes/Bulk',\n",
    "    'Fwd Avg Bytes/Bulk',\n",
    "    \n",
    "    'Bwd IAT Mean',\n",
    "    'Fwd IAT Mean',\n",
    "    'Flow IAT Mean',\n",
    "    \n",
    "    'Packet Length Mean',\n",
    "    'Bwd Packet Length Mean',\n",
    "    'Fwd Packet Length Mean',\n",
    "    \n",
    "    'Average Packet Size',\n",
    "    'Bwd Avg Packets/Bulk',\n",
    "    'Fwd Avg Packets/Bulk',\n",
    "    \n",
    "    'Avg Bwd Segment Size',\n",
    "    'Avg Fwd Segment Size',\n",
    "]\n",
    "\n",
    "std_cols = [\n",
    "    'Active Std',\n",
    "    'Idle Std',\n",
    "    \n",
    "    'Bwd IAT Std',\n",
    "    'Fwd IAT Std',\n",
    "    'Flow IAT Std',\n",
    "\n",
    "    'Packet Length Std',\n",
    "    'Packet Length Variance',\n",
    "    'Bwd Packet Length Std',\n",
    "    'Fwd Packet Length Std',\n",
    "]\n",
    "\n",
    "unused_cols = [\n",
    "    'Unnamed: 0',\n",
    "    'Flow ID',\n",
    "    'Source IP',\n",
    "    'Destination IP',\n",
    "    'SimillarHTTP',\n",
    "    'Label',\n",
    "    'Fwd Header Length.1'\n",
    "] + port_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddos_clean = ddos.copy().drop(columns=unused_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddos[ddos[\"Label\"] != 'Syn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign = ddos[ddos[\"Label\"] == 'BENIGN']\n",
    "syn = ddos[ddos[\"Label\"] == 'Syn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_port = max(ddos['Destination Port'].max(), ddos['Source Port'].max())\n",
    "max_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('fast_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "deaf3a77c670ae4bcde0102b8754366ef6094e7b1a1d30917591bfafe6a4ef0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
